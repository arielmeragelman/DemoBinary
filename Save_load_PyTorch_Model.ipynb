{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Save_load_PyTorch_Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMEXdlkQGiC5cEzAVVc89qG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binary-study/DemoBinary/blob/main/Save_load_PyTorch_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH4JsGKwsmsE"
      },
      "source": [
        "%mkdir checkpoint best_model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KvYtuIfGtBuQ",
        "outputId": "38759001-43b1-4b3a-f808-929236f094d1"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrOzSQZetqQu"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YV4Mj9muN8q",
        "outputId": "f74ffdb0-5f1a-400f-8871-5ff036234b4b"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "print(use_cuda)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH66k3vc4fpK"
      },
      "source": [
        "## **1. Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJJm3SmA4joW"
      },
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.5], [0.5])])\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "\n",
        "loaders = {\n",
        "    'train' : torch.utils.data.DataLoader(trainset,batch_size = 64,shuffle=True),\n",
        "    'test'  : torch.utils.data.DataLoader(testset,batch_size = 64,shuffle=True),\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfxGbgq8EaSM",
        "outputId": "22fc67f2-ae2a-4ffa-cc89-279e91da2a01"
      },
      "source": [
        "loaders"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': <torch.utils.data.dataloader.DataLoader at 0x7f1f93a6ff10>,\n",
              " 'train': <torch.utils.data.dataloader.DataLoader at 0x7f1fedc46850>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY41Lhbfum1U"
      },
      "source": [
        "## **2. Define Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA-Vnm1Cugnn"
      },
      "source": [
        "# Define your network ( Simple Example )\n",
        "class FashionClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        input_size = 784\n",
        "        self.fc1 = nn.Linear(input_size, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64,10)\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "        x = self.dropout(F.relu(self.fc4(x)))\n",
        "        x = F.log_softmax(self.fc5(x), dim=1)\n",
        "        return x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cSbmPoUyIs1",
        "outputId": "cbb627b7-2341-46d2-fe39-24d09c125853"
      },
      "source": [
        "# Create the network, define the criterion and optimizer\n",
        "model = FashionClassifier()\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# move model to GPU if CUDA is available\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FashionClassifier(\n",
            "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc5): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34_ZIbuoz6hp",
        "outputId": "eea02eb7-1969-4fd0-ee32-e36ec9d73f4b"
      },
      "source": [
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "# Print optimizer's state_dict\n",
        "print(\"Optimizer's state_dict:\")\n",
        "for var_name in optimizer.state_dict():\n",
        "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model's state_dict:\n",
            "fc1.weight \t torch.Size([512, 784])\n",
            "fc1.bias \t torch.Size([512])\n",
            "fc2.weight \t torch.Size([256, 512])\n",
            "fc2.bias \t torch.Size([256])\n",
            "fc3.weight \t torch.Size([128, 256])\n",
            "fc3.bias \t torch.Size([128])\n",
            "fc4.weight \t torch.Size([64, 128])\n",
            "fc4.bias \t torch.Size([64])\n",
            "fc5.weight \t torch.Size([10, 64])\n",
            "fc5.bias \t torch.Size([10])\n",
            "Optimizer's state_dict:\n",
            "state \t {}\n",
            "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZlWB8qF1Uhv"
      },
      "source": [
        "import shutil\n",
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "    f_path = checkpoint_path\n",
        "    torch.save(state, f_path)\n",
        "    if is_best:\n",
        "        best_fpath = best_model_path\n",
        "        shutil.copyfile(f_path, best_fpath)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLZA5KgpC_c1"
      },
      "source": [
        "def train(start_epochs, n_epochs, valid_loss_min_input, loaders, model, optimizer, criterion, use_cuda, checkpoint_path, best_model_path):\n",
        "    \"\"\"\n",
        "    Keyword arguments:\n",
        "    start_epochs -- the real part (default 0.0)\n",
        "    n_epochs -- the imaginary part (default 0.0)\n",
        "    valid_loss_min_input\n",
        "    loaders\n",
        "    model\n",
        "    optimizer\n",
        "    criterion\n",
        "    use_cuda\n",
        "    checkpoint_path\n",
        "    best_model_path\n",
        "    \n",
        "    returns trained model\n",
        "    \"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = valid_loss_min_input \n",
        "    \n",
        "    for epoch in range(start_epochs, n_epochs+1):\n",
        "        # initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## find the loss and update the model parameters accordingly\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            ## record the average training loss, using something like\n",
        "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## update the average validation loss\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # update average validation loss \n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "            \n",
        "        # calculate average losses\n",
        "        train_loss = train_loss/len(loaders['train'].dataset)\n",
        "        valid_loss = valid_loss/len(loaders['test'].dataset)\n",
        "\n",
        "        # print training/validation statistics \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch, \n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "        \n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'valid_loss_min': valid_loss,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "        }\n",
        "        \n",
        "        save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
        "        ## TODO: save the model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
        "            save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "            valid_loss_min = valid_loss\n",
        "            \n",
        "    # return trained model\n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lmQYFPQDzUz",
        "outputId": "43e583fc-a71e-435f-b711-fb096d9424f0"
      },
      "source": [
        "trained_model = train(1, 3, np.Inf, loaders, model, optimizer, criterion, use_cuda, \"./checkpoint/current_checkpoint.pt\", \"./best_model/best_model.pt\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.000010 \tValidation Loss: 0.000045\n",
            "Validation loss decreased (inf --> 0.000045).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.000007 \tValidation Loss: 0.000042\n",
            "Validation loss decreased (0.000045 --> 0.000042).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.000007 \tValidation Loss: 0.000041\n",
            "Validation loss decreased (0.000042 --> 0.000041).  Saving model ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSzjOLxaiyqo",
        "outputId": "d684eb8b-6129-4392-965f-e61fa92d4bd5"
      },
      "source": [
        "%ls ./best_model/"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best_model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d01QG-dei3z6",
        "outputId": "a0438d60-ff2b-4a20-f6d9-6c78a38ca9ff"
      },
      "source": [
        "%ls ./checkpoint/\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current_checkpoint.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpxpO5yRi8f3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dIK2-zpktNh"
      },
      "source": [
        "## **Loading the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uObPXQlOkvDg"
      },
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    valid_loss_min = checkpoint['valid_loss_min']\n",
        "    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5JLSEdmk0HJ",
        "outputId": "a46bd405-14a0-4385-9466-4e305d0c32f7"
      },
      "source": [
        "%pwd\n",
        "%ls"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mbest_model\u001b[0m/  \u001b[01;34mcheckpoint\u001b[0m/  \u001b[01;34mF_MNIST_data\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7Mnfh6qk57j",
        "outputId": "561c51f7-160d-4c0c-ebe4-33baba1d3992"
      },
      "source": [
        "model = FashionClassifier()\n",
        "# move model to GPU if CUDA is available\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FashionClassifier(\n",
            "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc5): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3xXHdxAlEnI"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "ckp_path = \"./checkpoint/current_checkpoint.pt\"\n",
        "model, optimizer, start_epoch, valid_loss_min = load_ckp(ckp_path, model, optimizer)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYDma7SvlWVO",
        "outputId": "c9648555-27ad-4bed-80e6-dbe3666edb88"
      },
      "source": [
        "print(\"model = \", model)\n",
        "print(\"optimizer = \", optimizer)\n",
        "print(\"start_epoch = \", start_epoch)\n",
        "print(\"valid_loss_min = \", valid_loss_min)\n",
        "print(\"valid_loss_min = {:.6f}\".format(valid_loss_min))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model =  FashionClassifier(\n",
            "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc5): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "optimizer =  Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            ")\n",
            "start_epoch =  4\n",
            "valid_loss_min =  4.095881013199687e-05\n",
            "valid_loss_min = 0.000041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYwqJADtmE6w",
        "outputId": "33c33246-def3-480f-ea7c-10f02db565fc"
      },
      "source": [
        "trained_model = train(start_epoch, 6, valid_loss_min, loaders, model, optimizer, criterion, use_cuda, \"./checkpoint/current_checkpoint.pt\", \"./best_model/best_model.pt\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4 \tTraining Loss: 0.000006 \tValidation Loss: 0.000038\n",
            "Validation loss decreased (0.000041 --> 0.000038).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 0.000006 \tValidation Loss: 0.000038\n",
            "Validation loss decreased (0.000038 --> 0.000038).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 0.000006 \tValidation Loss: 0.000035\n",
            "Validation loss decreased (0.000038 --> 0.000035).  Saving model ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6co71_gvmSdB",
        "outputId": "9bb68a4c-67bd-4846-a982-e9ed3d840f8e"
      },
      "source": [
        "trained_model.eval()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionClassifier(\n",
              "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc5): Linear(in_features=64, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Krrsn_zmZdR",
        "outputId": "cb3438a0-784e-46f7-8d35-f99b5884f30b"
      },
      "source": [
        "test_acc = 0.0\n",
        "for samples, labels in loaders['test']:\n",
        "    with torch.no_grad():\n",
        "        samples, labels = samples.cuda(), labels.cuda()\n",
        "        output = trained_model(samples)\n",
        "        # calculate accuracy\n",
        "        pred = torch.argmax(output, dim=1)\n",
        "        correct = pred.eq(labels)\n",
        "        test_acc += torch.mean(correct.float())\n",
        "\n",
        "print('Accuracy of the network on {} test images: {}%'.format(len(testset), round(test_acc.item()*100.0/len(loaders['test']), 2)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on 10000 test images: 87.49%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}